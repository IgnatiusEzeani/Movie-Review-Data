{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "Week 18 Lecture Demo.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IgnatiusEzeani/NLP-Lecture/blob/main/Week_18_Lab_Text_Feature_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np4jeQ0vhZvk"
      },
      "source": [
        "**Credit**: The example code below was taken from [Chapters 6 of the NLTK book](https://www.nltk.org/book/ch06.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPb1uVLUGpU4"
      },
      "source": [
        "# **Section 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKQmUn2SI24p"
      },
      "source": [
        "## Gender Identification\r\n",
        "\r\n",
        "NLTK has a wordlist corpus, `Names`, containing 8,000 first names categorized by gender. The male and female names are stored in separate files. Let's find names which appear in both files, i.e. names that are ambiguous for gender:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6-fTmlcsxy5"
      },
      "source": [
        "###**Import `nltk` and download the `name` corpus**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdIPt9_3KaTm"
      },
      "source": [
        "# !pip install nltk matplotlib ## Uncomment to install\r\n",
        "import nltk\r\n",
        "import random\r\n",
        "nltk.download('names')\r\n",
        "names = nltk.corpus.names "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oxQp3aktOUa"
      },
      "source": [
        "###**Names in both male and female list**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-PEqqK-P1U0"
      },
      "source": [
        "print(names.fileids())\r\n",
        "male_names = names.words('male.txt')\r\n",
        "female_names = names.words('female.txt')\r\n",
        "male_female = [w for w in male_names if w in female_names]\r\n",
        "print(len(male_female))\r\n",
        "for name in male_female[:20]:\r\n",
        "  print(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlXanISitogQ"
      },
      "source": [
        "\r\n",
        "###**Distribution of last letters**\r\n",
        "According to [NLTK](https://www.nltk.org/book/ch02.html#sec-lexical-resources) suggests that male and female names have some distinctive characteristics. Names ending in `a`, `e` and `i` are likely to be female, while names ending in `k`, `o`, `r`, `s` and `t` are likely to be male. Let's see..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJxOj6IAiCwV"
      },
      "source": [
        "cfd = nltk.ConditionalFreqDist(\r\n",
        "    (fileid, name[-1])\r\n",
        "    for fileid in names.fileids()\r\n",
        "    for name in names.words(fileid))\r\n",
        "cfd.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKTCnXVtulTM"
      },
      "source": [
        "###**Feature extractor functions**\r\n",
        "Let's build a classifier to model these differences more precisely. The first step in creating a classifier is deciding what features of the input are relevant, and how to encode those features. For this example, we'll start by just looking at the final letter of a given name.\r\n",
        "\r\n",
        "The following feature extractors function builds a dictionary containing relevant information about a given name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkqwZA97-kco"
      },
      "source": [
        "# feature extractor 1\r\n",
        "def gender_features(word):\r\n",
        "  return {'last_letter': word[-1]}\r\n",
        "\r\n",
        "# feature extractor 2\r\n",
        "def gender_features2(name):\r\n",
        "    features = {}\r\n",
        "    features[\"first_letter\"] = name[0].lower()\r\n",
        "    features[\"last_letter\"] = name[-1].lower()\r\n",
        "    for letter in 'abcdefghijklmnopqrstuvwxyz':\r\n",
        "        features[\"count({})\".format(letter)] = name.lower().count(letter)\r\n",
        "        features[\"has({})\".format(letter)] = (letter in name.lower())\r\n",
        "    return features\r\n",
        "\r\n",
        "# feature extractor 3\r\n",
        "def gender_features3(word):\r\n",
        "  return {'suffix1': word[-1:], 'suffix2': word[-2:]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mG4qDaRuLg04"
      },
      "source": [
        "###**Compiling the training instances**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkva_riO-kZh"
      },
      "source": [
        "# Building the training instances\r\n",
        "labeled_names = ([(name, 'male') for name in names.words('male.txt')] \r\n",
        "                 + [(name, 'female') for name in names.words('female.txt')])\r\n",
        "random.shuffle(labeled_names)\r\n",
        "# len(labeled_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6O8QNZlKnLl"
      },
      "source": [
        "###**Train-DevTest-Test Split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M51A2vI48Mj3"
      },
      "source": [
        "# train-devtest-test split\r\n",
        "train_names = labeled_names[1500:]\r\n",
        "devtest_names = labeled_names[500:1500]\r\n",
        "test_names = labeled_names[:500]\r\n",
        "print(len(train_names), len(devtest_names), len(test_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLRZLY_mKbcB"
      },
      "source": [
        "###**Extracting the features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CxljUFP9LgE"
      },
      "source": [
        "# Extracting the features\r\n",
        "train_set = [(gender_features(n), gender) for (n, gender) in train_names]\r\n",
        "devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\r\n",
        "test_set = [(gender_features(n), gender) for (n, gender) in test_names]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bEVZPNBKOat"
      },
      "source": [
        "###**Training and Testing the Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9_KWPJQ6JHI"
      },
      "source": [
        "# Training the classifier\r\n",
        "random.shuffle(train_set)\r\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\r\n",
        "\r\n",
        "# apply the classifier to the development test\r\n",
        "print(\"Accuracy = \", nltk.classify.accuracy(classifier, devtest_set))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN8fWZAtHbh4"
      },
      "source": [
        "###**Building the Error List**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn3_5EZr90tR"
      },
      "source": [
        "# error analysis\r\n",
        "errors = []\r\n",
        "for (name, tag) in devtest_names:\r\n",
        "  guess = classifier.classify(gender_features(name))\r\n",
        "  if guess != tag:\r\n",
        "    errors.append((tag, guess, name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnD217e5HKMA"
      },
      "source": [
        "###**Show errors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N_Md01I-ZNK"
      },
      "source": [
        "# Error list\r\n",
        "print(\"Errors:\", len(errors))\r\n",
        "for (tag, guess, name) in sorted(errors[:20]):\r\n",
        "  print('correct={:<8} guess={:<8s} name={:<30}'.format(tag, guess, name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQlZcaUpGrBd"
      },
      "source": [
        "###**Most informative features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRZxc8u7-hOX"
      },
      "source": [
        "# Most informative features\r\n",
        "classifier.show_most_informative_features(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFRN2Gf_GQPM"
      },
      "source": [
        "###**Classifying other names**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3dAeUx_-kTe"
      },
      "source": [
        "print(classifier.classify(gender_features('Neo')))\r\n",
        "# Output: 'male'\r\n",
        "print(classifier.classify(gender_features('Trinity')))\r\n",
        "# Output: 'female'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O9VhNdMFM0o"
      },
      "source": [
        "###**Classifying your name**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et4DTQyRFN9F"
      },
      "source": [
        "## Uncomment and modify below to classify your name with your best classifier\r\n",
        "# print(classifier.classify(gender_features(<your name>))) #remember to change your "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-6SwAlzXzJH"
      },
      "source": [
        "##**Task 1**\r\n",
        "\r\n",
        "Write a code that trains three different classifiers (`classifier1`, `classifier2` and `classifier3`) using the three feature extractor functions defined above `gender_features()`, `gender_features2()` and `gender_features3()`.\r\n",
        "\r\n",
        "1. Apply the the three classifiers to the `dev_test` and for each report the *percentage accuracy*, *error count*, *error list*.  **Which of the feature extraction methods performed best on classifying the `dev_test`? Can you explain why?**\r\n",
        "\r\n",
        "2. Apply the best performing classfier to the `test_set`. **What is the classification accuracy, error list?**\r\n",
        "\r\n",
        "3. Modify your feature extractor or any part of the code to see if you can improve the accuracy score?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVGFx12KbM8-"
      },
      "source": [
        "# 1. Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imSXltFlck4M"
      },
      "source": [
        "# 2. Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWkYxTMFclEk"
      },
      "source": [
        "# 3. Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v485qfc3crx9"
      },
      "source": [
        "---\r\n",
        "# **Section 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyoUIJsVdII9"
      },
      "source": [
        "## Document Classification\r\n",
        "First, we construct a list of documents, labeled with the appropriate categories. For this example, we've chosen the Movie Reviews Corpus, which categorizes each review as `positive` or `negative`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1uqrbxjdQtE"
      },
      "source": [
        "nltk.download('movie_reviews')\r\n",
        "from nltk.corpus import movie_reviews\r\n",
        "documents = [(list(movie_reviews.words(fileid)), category) \r\n",
        "              for category in movie_reviews.categories()\r\n",
        "              for fileid in movie_reviews.fileids(category)]\r\n",
        "random.shuffle(documents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r8roRQcdtNK"
      },
      "source": [
        "Next, we define a feature extractor for documents, so the classifier will know which aspects of the data it should pay attention to. For document topic identification, we can define a feature for each word, indicating whether the document contains that word.\r\n",
        "\r\n",
        "To limit the number of features that the classifier needs to process, we begin by constructing a list of the _2000 most frequent words_ in the overall corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jGPUGs5dvUj"
      },
      "source": [
        "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\r\n",
        "word_features = list(all_words)[:2000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEfXEh_reYsy"
      },
      "source": [
        "We can then define a feature extractor `document_features()` that simply checks whether each of these words is present in a given document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FALh7ieLpGqF"
      },
      "source": [
        "def document_features(document):\r\n",
        "    document_words = set(document)\r\n",
        "    features = {}\r\n",
        "    for word in word_features:\r\n",
        "        features['contains({})'.format(word)] = (word in document_words)\r\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrkCWfKppk7K"
      },
      "source": [
        "The reason for computing the set of all words in a document in Line 2, rather than just checking if word in document, is that checking whether a word occurs in a set is much faster than checking whether it occurs in a list.\r\n",
        "\r\n",
        "Now, let's test our feature extractor by looking at the words that appeared in this positive review file `pos/cv957_8737.txt`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdfFWO0Tpiyw"
      },
      "source": [
        "print(document_features(movie_reviews.words('pos/cv957_8737.txt'))) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6SwETS0ewgK"
      },
      "source": [
        "Now that we've defined our feature extractor, we can use it to train a classifier to label new movie reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKPrGRy5exFN"
      },
      "source": [
        "featuresets = [(document_features(d), c) for (d,c) in documents]\r\n",
        "train_set, test_set = featuresets[100:], featuresets[:100]\r\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "786mWwbgqxCs"
      },
      "source": [
        "To check how reliable the resulting classifier is, we compute its accuracy on the test set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UpUPCADe2Gu"
      },
      "source": [
        "print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUSJiIFSozFO"
      },
      "source": [
        "Again, we can use `show_most_informative_features()` to find out which features the classifier found to be most informative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ud0HnLcoxz1"
      },
      "source": [
        "classifier.show_most_informative_features()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EEmNWr_rrgP"
      },
      "source": [
        "Apparently in this corpus, a review that mentions **shoddy** is almost 7 times more likely to be negative than positive, while a review that mentions **singers** is about 6 times more likely to be positive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC-3PYuqrcEH"
      },
      "source": [
        "##**Task 2**\r\n",
        "\r\n",
        "The document feature extractor checks whether each word is present in a given document. Can you create other feature extractors as defined below?: \r\n",
        "\r\n",
        "1. `document_features2()`: uses the word frequency counts (and not their presence) as features.\r\n",
        "\r\n",
        "2. `document_features3()`: extracts and uses the bigrams present in the document as features\r\n",
        "\r\n",
        "3. `document_features4()`: combine the unigrams (words) and bigram presence as features\r\n",
        "\r\n",
        "Test your results with these and share your observation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyIn1zzdy8PO"
      },
      "source": [
        "# 1. Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv1T0DH5y9hn"
      },
      "source": [
        "# 2. Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBYMKwgJy9E-"
      },
      "source": [
        "# 3. Your code here"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}